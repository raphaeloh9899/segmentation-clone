{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97d76cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@3211.722] global loadsave.cpp:244 findDecoder imread_('0001TP_006690.png'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m pspnet_101_voc12() \u001b[38;5;66;03m# load the pretrained model trained on Pascal VOC 2012 dataset\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# load any of the 3 pretrained models\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_segmentation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43minp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0001TP_006690.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_fname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0001TP_006690.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     17\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/image-segmentation-keras-master/keras_segmentation/predict.py:148\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(model, inp, out_fname, checkpoints_path, overlay_img, class_names, show_legends, colors, prediction_width, prediction_height, read_image_type)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inp, six\u001b[38;5;241m.\u001b[39mstring_types):\n\u001b[1;32m    146\u001b[0m     inp \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(inp, read_image_type)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(\u001b[43minp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inp\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inp\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage should be h,w,3 \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    150\u001b[0m output_width \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39moutput_width\n\u001b[1;32m    151\u001b[0m output_height \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39moutput_height\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras_segmentation.pretrained import pspnet_50_ADE_20K , pspnet_101_cityscapes, pspnet_101_voc12\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "model = pspnet_50_ADE_20K() # load the pretrained model trained on ADE20k dataset\n",
    "\n",
    "model = pspnet_101_cityscapes() # load the pretrained model trained on Cityscapes dataset\n",
    "\n",
    "model = pspnet_101_voc12() # load the pretrained model trained on Pascal VOC 2012 dataset\n",
    "\n",
    "# load any of the 3 pretrained models\n",
    "\n",
    "out = model.predict_segmentation(\n",
    "    inp=\"0001TP_006690.png\",\n",
    "    out_fname=\"0001TP_006690.png\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5b5b8d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "ann_img = np.zeros((30,30,3)).astype('uint8')\n",
    "ann_img[ 3 , 4 ] = 1 # this would set the label of pixel 3,4 as 1\n",
    "\n",
    "cv2.imwrite( \"ann_1.png\" ,ann_img )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3818fbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_segmentation.models.unet import vgg_unet\n",
    "from tensorflow import keras\n",
    "model = vgg_unet(n_classes=51 ,  input_height=416, input_width=608  )\n",
    "\n",
    "model.train(\n",
    "    train_images =  \"dataset1/images_prepped_train/\",\n",
    "    train_annotations = \"dataset1/annotations_prepped_train/\",\n",
    "    checkpoints_path = \"/tmp/vgg_unet_1\" , epochs=5\n",
    ")\n",
    "\n",
    "out = model.predict_segmentation(\n",
    "    inp=\"dataset1/images_prepped_test/0016E5_07965.png\",\n",
    "    out_fname=\"/tmp/out.png\"\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(out)\n",
    "\n",
    "# evaluating the model \n",
    "print(model.evaluate_segmentation( inp_images_dir=\"dataset1/images_prepped_test/\"  , annotations_dir=\"dataset1/annotations_prepped_test/\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e724381",
   "metadata": {},
   "outputs": [],
   "source": [
    "python -m keras_segmentation verify_dataset \\\n",
    " --images_path=\"dataset1/images_prepped_train/\" \\\n",
    " --segs_path=\"dataset1/annotations_prepped_train/\"  \\\n",
    " --n_classes=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60c2a1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "python -m keras_segmentation train \\\n",
    " --checkpoints_path=\"path_to_checkpoints\" \\\n",
    " --train_images=\"dataset1/images_prepped_train/\" \\\n",
    " --train_annotations=\"dataset1/annotations_prepped_train/\" \\\n",
    " --val_images=\"dataset1/images_prepped_test/\" \\\n",
    " --val_annotations=\"dataset1/annotations_prepped_test/\" \\\n",
    " --n_classes=50 \\\n",
    " --input_height=320 \\\n",
    " --input_width=640 \\\n",
    " --model_name=\"vgg_unet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "483c8344",
   "metadata": {},
   "outputs": [],
   "source": [
    "python -m keras_segmentation predict \\\n",
    " --checkpoints_path=\"path_to_checkpoints\" \\\n",
    " --input_path=\"dataset1/images_prepped_test/\" \\\n",
    " --output_path=\"path_to_predictions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eee14e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "python -m keras_segmentation predict_video \\\n",
    " --checkpoints_path=\"path_to_checkpoints\" \\\n",
    " --input=\"path_to_video\" \\\n",
    " --output_file=\"path_for_save_inferenced_video\" \\\n",
    " --display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a601643",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
